---
title: Paper accepted by TMLR.
subtitle: Adaptive algorithm is the future of the machine learning.  
# subtitle: Welcome ðŸ‘‹ We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.

# Summary for listings and search engines
summary: ðŸ‘‹ AI-SARAH is accepted by TMLR for publication. 

# Link this post with a project
projects: []

# Date published
date: '2023-02-22T00:00:00Z'

# Date updated
lastmod: '2023-02-22T00:00:00Z'

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: true

# Featured image
# Place an image named `featured.jpg/png` in this page's folder and customize its options here.
image:
  caption: 'Image credit: [**TMLR**](https://www.jmlr.org/tmlr/index.html)'
  focal_point: 'Bottom'
  placement: 1
  preview_only: true
  # filename: ibmtech2023-2.jpg

authors:
  - admin

tags:
  - Machine Learning
  - Adaptive Algorithms
  - Academic_Latest
  - latest

categories:
  - Research
  - Academic Space
---


## ðŸ“£ ðŸ“£ ðŸ“£

One of my co-authored papers, [*AI-SARAH: Adaptive and Implicit Stochastic Recursive Gradient Methods*](https://www.zhengqxhs.com/publication/aisarah/) was accepted by [**Transactions of Machine Learing Research**](https://www.jmlr.org/tmlr/index.html) (TMLR). 
{style="text-align: justify;"}

AI-SARAH is the first plug-n-play algorithm in the realm of stochastic recursive gradient method. It automatically adapts to ML models and can save hundreds, if not thousands, of experiments performing hyper-parameter fine-tuning. It is super easy and efficient to implement in practice, and it outperforms many state-of-the-art methods, including ADAM and SGD, in solving machine learning problems.
{style="text-align: justify;"}

